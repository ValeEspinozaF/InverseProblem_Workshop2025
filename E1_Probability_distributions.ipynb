{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and Inverse Problems 2025\n",
    "##  Exercise 1 - Probability distributions\n",
    "\n",
    "### Author(s), contact(s), and dates:\n",
    "- Author: Valentina Espinoza Fern√°ndez (University of Copenhagen)\n",
    "- Email:  vf@ign.ku.dk\n",
    "- Date:   9th of January 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabel of contents\n",
    "* [Common distributions](#common-distributions)\n",
    "* [Generate Gaussian distributions](#generate_gaussian)\n",
    "* [Fit Gaussian distributions](#fit_gaussian)\n",
    "* [Goodness of fit](#goodness_of_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore and familiarize ourselves with the key parameters that define the most common probability distributions in statistics, focusing on Gaussian distributions. With Python, you will learn how to generate your own Gaussian sample, go back and fit this data to a Gaussian distribution, and learn to evaluate the goodness of said fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public dependencies\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common distributions  <a  class=\"anchor\" id=\"common-distributions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will visualize the shape of the most common distributions, that is, the Uniform, Exponential and Gaussian distribution. A formal construction of a Gaussian sample is show in the next section. \n",
    "1. Can you infer how the parameters within each function (e.g., `loc`, `scale`) affect the shape of the distribution? \n",
    "2. For the Gaussian distribution, do you know the formal names for these parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Uniform distribution\n",
    "array_uniform = np.random.uniform(low=0.5, high=6.5, size=1000)\n",
    "sns.histplot(array_uniform, bins=6, ax=ax1)\n",
    "ax1.set(title=\"Uniform distribution\")\n",
    "\n",
    "# Exponential distribution\n",
    "array_exp = np.random.exponential(scale=1.0, size=1000)\n",
    "sns.histplot(array_exp, bins=20, ax=ax2)\n",
    "ax2.set(title=\"Exponential distribution\");\n",
    "\n",
    "# Gaussian (normal) distribution\n",
    "array_gaussian = np.random.normal(loc=5.0, scale=1.0, size=1000)\n",
    "sns.histplot(array_gaussian, bins=20, ax=ax3)\n",
    "ax3.set(title=\"Gaussian (normal) distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `size` parameter, it determines the size of the sample. Can you realistically measure something 1000 times? \n",
    "\n",
    "3. Experiment with the parameters `size` and `bins` to see their impact on the shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Gaussian distributions  <a class=\"anchor\" id=\"generate_gaussian\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000        # Number of samples\n",
    "mu0 = 5.0               # Mean (original)\n",
    "std0 = 1.0              # Standard deviation (original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create array of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_normal = np.random.normal(mu0, std0, n_samples)       # Use numpy to generate n_samples values following a Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 20         # Number of bins for the histogram\n",
    "\n",
    "\n",
    "# Plot the histogram (using the seaborn package) \n",
    "ax = sns.histplot(array_normal, bins=n_bins)             \n",
    "\n",
    "# Embellish your plot with labels and a title\n",
    "ax.set(xlabel='Students grades',                   \n",
    "       ylabel='Frequency', \n",
    "       title='Samples=%d, Bins=%d' % (n_samples, n_bins)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may add the parameter `kde=True` to the `sns.histplot` function to plot a curve that follows the histogram distribution. To simply plot the curve try the command `ax = sns.kdeplot(array_normal)` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Gaussian distributions <a class=\"anchor\" id=\"fit_gaussian\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Gaussian curve can be parametrized into a mean and standard deviation. Lets pretend we forgot the the parameters that constructed the above array (`mu0, std0`). We do know they resemble a Gaussian curve (we *know* they do come from one), so we will fit the data to a normal distribution and by that estimate its mean and standard deviation (`mu, std`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for Gaussian curves\n",
    "def gaussian(x, mean, std_dev):            \n",
    "    return stats.norm.pdf(x, mean, std_dev)  # We could write the formal equation or use scipy's pre-written function\n",
    "\n",
    "# Extract the x-coordinates of the array\n",
    "xmin, xmax = np.min(array_normal), np.max(array_normal)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "\n",
    "# Fit a Gaussian distribution with scipy\n",
    "mu, std = stats.norm.fit(array_normal)    # Estimate the mean(mu) and standard deviation (std) from a given array of values\n",
    "\n",
    "# Calculate the y-values for the x-array based on a Gaussian curve with the fitted mu and std values\n",
    "pdf = gaussian(x, mu, std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original data\n",
    "ax = sns.histplot(array_normal, bins=n_bins, label=\"data\")\n",
    "bin_width = [patch.get_width() for patch in ax.patches][0]        # Extract binwidth from plot\n",
    "\n",
    "# Plot the fitted Gaussian curve (scale to y-values to histogram)\n",
    "pdf_scaled = pdf * len(array_normal) * bin_width\n",
    "ax.plot(x, pdf_scaled, color='red', label='Gaussian fit')  \n",
    "  \n",
    "\n",
    "# Polish plot\n",
    "ax.legend()\n",
    "ax.set(xlabel='Students grades', title='Mean=%.2f, Std=%.2f' % (mu, std));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit is quite good, as we know the fitted `mu` and `std` closely resemble the original `mu0` and `std0` values. \n",
    "4. Do you expect a reasonable fit if `array_normal` was only 100 elements in size? Change the value of `n_samples` to 100 and then 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness of fit <a class=\"anchor\" id=\"goodness_of_fit\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the goodness of fit by comparing `mu` and `mu0` is valid, but we can do better. Lets take avantage of the chisquare methods to compare the fit between the original parameters and the fitted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = np.random.normal(loc=5.0, scale=1.0, size=200)    # We use an sample with 200 elements, a mean of 5.0 and std of 1.0\n",
    "\n",
    "# Define the bins (chisquare compares binned frequencies!)\n",
    "n_bins = 20\n",
    "bin_edges = np.linspace(0, 10, n_bins+1)\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "# Extract the \"observed\" frequencies\n",
    "observed_freq, _ = np.histogram(data, bins=bin_edges, density=True)\n",
    "\n",
    "\n",
    "# Calculate \"expected\" frequencies for the fitted normal distribution (let say got mu=5.01 and std=0.96)\n",
    "mean_exp = 5.1\n",
    "std_exp = 0.96\n",
    "expected_freq = stats.norm.pdf(bin_centers, loc=mean_exp, scale=std_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the chi-square goodness of fit test\n",
    "chi2_stat, p_value = stats.chisquare(observed_freq, expected_freq, ddof=2)      # ddof is the number of estimated parameters in the fit, mu and std.\n",
    "\n",
    "# Plot results\n",
    "ax = sns.histplot(data, bins=bin_edges, label='Observed', color='blue', alpha=0.5, stat='density')  # Plot \"observed\" frequencies\n",
    "ax.plot(bin_centers, expected_freq, label='Expected', color='red', marker='o')                      # Plot \"expected\" frequencies\n",
    "\n",
    "ax.set(title='Chi-square: %.2f, p-value: %.3f' % (chi2_stat, p_value))\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Try changing the `data` array for an array with less samples, e.g., `size = 10`. See how that affects the P-Value and therefore our confidence in the distribution of the data. 6. Try instead to replace the expected Gaussian distribution to one slightly more off (e.g., `mean_exp = 5.2`) and see the fit. \n",
    "7. Maybe replace the data distribution for something else entirely, e.g., `data = np.random.uniform(size=100)`. \n",
    "\n",
    "Do you trust the P-value to guide your conclusions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
